import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.callbacks import ModelCheckpoint

def preprocess_data(file_path, le_author=None, le_files_modified=None, le_test_failed=None):
    df = pd.read_csv(file_path)

    if le_files_modified is None:
        le_files_modified = LabelEncoder()
    if le_test_failed is None:
        le_test_failed = LabelEncoder()

    df['files_modified'] = le_files_modified.fit_transform(df['files_modified'])
    df['test_failed'] = le_test_failed.fit_transform(df['test_failed'])

    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df)
    return scaled_data, scaler, le_files_modified, le_test_failed

def train_autoencoder_model(train_data):
    input_dim = train_data.shape[1]
    input_layer = Input(shape=(input_dim,))
    encoder = Dense(32, activation="relu")(input_layer)
    encoder = Dense(16, activation="relu")(encoder)
    decoder = Dense(32, activation="relu")(encoder)
    decoder = Dense(input_dim, activation="sigmoid")(decoder)

    autoencoder = Model(inputs=input_layer, outputs=decoder)
    autoencoder.compile(optimizer='adam', loss='mse')

    checkpoint = ModelCheckpoint(model_save_path, save_best_only=True, verbose=1)
    autoencoder.fit(train_data, train_data, epochs=100, batch_size=32, shuffle=True, validation_split=0.2, callbacks=[checkpoint])

    return autoencoder

def predict_flaky_probability(autoencoder, test_data, test_cases, le_files_modified):
    predictions = autoencoder.predict(test_data)
    mse = np.mean(np.power(test_data - predictions, 2), axis=1)
    flaky_probabilities = mse / np.max(mse)

    result = pd.DataFrame({'test_case': test_cases, 'flaky_probability': flaky_probabilities})
    result['files_modified'] = le_files_modified.inverse_transform(test_data[:, 1])  # Inverse transform the encoded files_modified
    return result

train_file_path = 'merged_final.csv'
model_save_path = 'saved_model.h5'
train_data, scaler, le_files_modified, le_test_failed = preprocess_data(train_file_path)
autoencoder = train_autoencoder_model(train_data)
autoencoder.save(model_save_path)

loaded_autoencoder = load_model(model_save_path)

test_file_path = 'test.csv'
output_file_path = 'output.csv'
test_data, _, _, test_cases = preprocess_data(test_file_path, le_files_modified, le_test_failed)
result = predict_flaky_probability(loaded_autoencoder, test_data, test_cases, le_files_modified)
result.to_csv(output_file_path, index=False)
